---
title: "SocialNetwork_assignment1"
author: "Yu Tian"
date: "February 24, 2015"
output: html
---

I have an undirected unvalued social network of 87 yelp users with attributes on them. I got the original data from Yelp’s Academic Dataset website (https://www.yelp.com/academic_dataset). The information about 366715 yelp users can be found in the contained .json file “yelp_academic_dataset_user.json”. Information includes 1) user’s name; 2) user’s yelp id; 3) when did the user start using yelp; 4) votes the user received across all his/her reviews; 5) compliments the user received form other yelp users; 6) average rating the user gave to businesses; 7) how many fans the user have; 8) who is the user befriend with (will explain in more details later). Given the huge size of the original network, I applied a sampling process to get a sample graph of size 87, with everybody in this network at least connected to 4 of the others. All the data massage including extracting data, data cleaning, and sampling are done in python, the attribute data and adjacency matrix is obtained using my python script as well.
I’ll skip the python part of data cleaning, the formatted data I’m using in R are from two .csv files – one is the attributes information for each one of the 87 users, the other is an adjacency matrix describing the connection between users in the network. 
Here are the explanations for the attributes of nodes in the network:

*“yelping_since”: in which year the user started using yelp, the original data has this variable coded as “yyyy-mm”, here I only extracted the “year” (“yyyy”), and it ranges from “2004” to “2011”;

*“votes”: the count for votes the user received across all his/her reviews. I am counting the aggregate votes for “funny”, “useful” and “cool” altogether. 

*“review_count”: the count for reviews the user wrote for all businesses. 

*“fans”: number of fans the user have. Fans are people who follow the user but are not followed back by the user.

*“average_stars”: average value of “stars” the user gave to all restaurants, ranges from 1 to 5.

*“compliments”: count for compliment the user received from other users.


```{r yelp: preparing data}
library(igraph)
setwd("/Users/yutian/Documents/QMSS/2015spring/DataViz/4NYDine")

# read in attributes
attrb <- read.csv("data/yelp_network_attribute.csv",header=F,row.names=NULL,check.names=FALSE)
colnames(attrb) <- c('yelping_since','votes','review_count','user_id','name','fans','average_stars','compliments')
head(attrb)
summary(attrb)

# read in adjacency matrix in .csv format
adj_d <- read.csv("data/yelp_network_adjmtx.csv",header=F,row.names=NULL,check.names=FALSE)
# convert to matrix and graph
adj_mtx <- as.matrix(adj_d)
adj_mtx_g <- graph.adjacency(adj_mtx,mode='undirected',weighted=NULL)

# assign attributes to vertex
V(adj_mtx_g)$name <- as.character(attrb$name)
V(adj_mtx_g)$user_id <- as.character(attrb$user_id)
V(adj_mtx_g)$yelping_since <- attrb$yelping_since
V(adj_mtx_g)$votes <- attrb$votes
V(adj_mtx_g)$review_count <- attrb$review_count
V(adj_mtx_g)$fans <- attrb$fans
V(adj_mtx_g)$average_stars <- attrb$average_stars
V(adj_mtx_g)$compliments <- attrb$compliments
```

Basic topographic information:
a.  Nature and direction of the ties: 
In the original data, we have for each user a list of other yelp users that the user is befriend with. Given how Yelp defines “friends” – people who are following each other, therefore every tie represents both an incoming and an outgoing tie between the two users it connects. Thus, ties in this network are mutual friend ties, then it could be considered as undirected.
b.	Overall density:
I ran graph.density() in R and get the overall density of the network = 0.1363272.
c.	Distribution of the categories and variables of attributes.


```{r yelp: overall network}
plot(adj_mtx_g, layout=layout.fruchterman.reingold)

graph.density(adj_mtx_g)

hist(attrb$yelping_since, main="Distribution of starting year on yelp",xlab="year" )
hist(attrb$votes, main="Distribution of number of votes",xlab="numebr of votes" )
hist(attrb$review_count, main="Distribution of reviews",xlab="numebr of reviews" )
hist(attrb$average_stars, main="Distribution of average rating",xlab="average rating" )
hist(attrb$compliments, main="Distribution of compliments",xlab="number of compliments" )
hist(attrb$fans, main="Distribution of number of fans",xlab="number of fans" )

```

To understand the structure of the whole network, we apply different coummity partitioning base on different criteria.
```{r community}
eb <- edge.betweenness.community (adj_mtx_g, directed = F, edge.betweenness = TRUE, merges = TRUE,bridges=TRUE,modularity=TRUE,membership=TRUE) 
plot(eb,adj_mtx_g)

wt<-walktrap.community(adj_mtx_g,steps=200,modularity=TRUE)#,labels=TRUE) ##run random walk partitioning
plot(wt,adj_mtx_g) ##plotR-Wpartitioning 

lp=label.propagation.community(adj_mtx_g) ##runlabelpropogationpartitioning 
plot(lp,adj_mtx_g) ##plotL-Ppartitioning

## compare these methods to each other
compare(eb, wt, method= c("nmi")) 
compare(eb, wt, method= c("rand")) 
compare(eb, wt, method= c("adjusted.rand"))

compare(eb, lp, method= c("nmi")) 
compare(eb, wt, method= c("rand")) 
compare(eb, lp, method= c("adjusted.rand"))

## get the results in a dataframe 
girvan <- data.frame(eb$membership) 
rw <- data.frame(wt$membership)
lpm <- data.frame(lp$membership) 

fd <- cbind(attrb, girvan, rw, lpm) 
```

Then we switch to ego network perspective and see how ego's social circle is influenced by ego's attribtues.
```{r yelp: ego network measurements}
# measures on vertex
degree <- degree(adj_mtx_g, loops=T, normalized=T)
btwn <- betweenness(adj_mtx_g, directed = F,normalized=T)
close <- closeness(adj_mtx_g, mode = c("all"),normalized=T)
eigen <- evcent(adj_mtx_g,directed = F)
alpha_centrality <- alpha.centrality(adj_mtx_g)
eigen_ctl_scores <- evcent(adj_mtx_g,directed = F)

df <- data.frame(name = attrb$name)
df <- cbind(df,degree, btwn, close, eigen$vector, alpha_centrality, eigen_ctl_scores$vector, V(adj_mtx_g)$yelping_since,V(adj_mtx_g)$votes, V(adj_mtx_g)$review_count,V(adj_mtx_g)$fans ,V(adj_mtx_g)$average_stars ,V(adj_mtx_g)$compliments)
#head(df)
colnames(df) <- c("name", "degree","betweenness", "closeness","eigenvector", "alpha_centrality" ,"eigen_control_scores","yelping_since", "votes", "review_count", "fans", "average_stars", "compliments")

df_ctrl <- df[,c(-6,-7)]
```


Here is a covariance matrix between centrality measures:
```{r covariance matrix}
cor_mtx <- cor(df_ctrl[,c(2,3,4,5)]) 
```

Start least square regression:

Even though I still think it’s problematical to directly use the attributes from the entire network to see their influence on the smaller network centrality measures, I’m just running these regressions on the purpose of practice. Therefore I’m making an ambitious assumption here that attributes from the entire network are proportional to the sample network, so that can be directly used in the sample network.

•  “yelping_since”: as the year become smaller, degree measure should become more central.
The more time the user has been using yelp, the more friends he/she has. I would assume a new user should always have less connections compared with an older user. However, it doesn’t necessarily make him/her a more important person in the network, even to some degree and some cased it will, we will see.

•	“votes” and “compliments”: as the number become bigger, degree and closeness measures should become more central.
“vote” and “compliments” are the response the user received from other users on Yelp, thus indicate how influential the user is in the network. As the person become more influential, I think the measures on degree and closeness would all become larger, however I need to find out if betweenness and eigenvector would become larger as well.

•	 “review_count”: as the number becomes bigger, degree and betweenness measures would become bigger as well.
Number of review indicates how active the user is on Yelp. I would assume the more active the user is, the more likely he/she is acting as the information spreader.

•	“fans”: as the number becomes bigger, degree, closeness, betweenness and eigenvector would all become bigger.
The number of fans the person has on social network site is considered the most powerful, who is the most influential, a good information spreader and usually better connected to other well-connected person as well.

•	 “average_stars”: not necessarily has influence on centrality measures.

```{r chart}
library(gclus)
covar_data <- df_ctrl

# degree
data <- covar_data[,c(-1,-3,-4,-5)]
covar_data.cor <- cor(data)
covar_data.color <- dmat.color(covar_data.cor, breaks=c(-1,-.7,-.5,0,.5,.7,1), colors =cm.colors(7,alpha = .9))
covar_data.o <- order.single(covar_data.cor)
cpairs(data,panel.colors=covar_data.color, gap=.5,main="covariance matrix: degree centrality")

# betweenness
data <- covar_data[,c(-1,-2,-4,-5)]
covar_data.cor <- cor(data)
covar_data.color <- dmat.color(covar_data.cor, breaks=c(-1,-.7,-.5,0,.5,.7,1), colors =cm.colors(7,alpha = .9))
covar_data.o <- order.single(covar_data.cor)
cpairs(data,panel.colors=covar_data.color, gap=.5,main="covariance matrix: betweenness centrality")

# closeness
data <- covar_data[,c(-1,-2,-3,-5)]
covar_data.cor <- cor(data)
covar_data.color <- dmat.color(covar_data.cor, breaks=c(-1,-.7,-.5,0,.5,.7,1), colors =cm.colors(7,alpha = .9))
covar_data.o <- order.single(covar_data.cor)
cpairs(data,panel.colors=covar_data.color, gap=.5,main="covariance matrix: closeness centrality")

# eigenvector
data <- covar_data[,c(-1,-2,-3,-4)]
covar_data.cor <- cor(data)
covar_data.color <- dmat.color(covar_data.cor, breaks=c(-1,-.7,-.5,0,.5,.7,1), colors =cm.colors(7,alpha = .9))
covar_data.o <- order.single(covar_data.cor)
cpairs(data,panel.colors=covar_data.color, gap=.5,main="covariance matrix: eigenvector centrality")

# all
data <- covar_data[,c(-1)]
covar_data.cor <- cor(data)
covar_data.color <- dmat.color(covar_data.cor, breaks=c(-1,-.7,-.5,0,.5,.7,1), colors =cm.colors(7,alpha = .9))
covar_data.o <- order.single(covar_data.cor)
cpairs(data,covar_data.o,covar_data.color, gap=.5,main="covariance matrix")
```



```{r regression 1}
colnames(df_ctrl)

fit1 <- lm(data = df_ctrl,degree ~ yelping_since + votes + review_count + fans + compliments)
summary(fit1)

fit1 <- lm(data = df_ctrl,degree ~ yelping_since + votes + fans + compliments)
summary(fit1)

fit1 <- lm(data = df_ctrl,degree ~ yelping_since + votes + fans)
summary(fit1)
plot(fit1)
plot(fit1$fitted.values,df_ctrl$degree)

r <- fit1$residuals
left <- min(r)
right <- max(r)
diff <- (right - left)/10
left <- left - diff
right <- right + diff
breaks <- seq(left, right, diff)
hist(r, breaks,main="Histogram of residuals",xlab = "residuals",las=1)
par(new=TRUE)   
plot(density(r), col=2,xlim=c(left,right), yaxt="n", xaxt="n",bty='n', xlab="", ylab="", main='')

```

```{r regression 2}
fit2 <- lm(data = df_ctrl,closeness ~ votes  + fans +compliments)
summary(fit2)
fit2 <- lm(data = df_ctrl,closeness ~ votes  + fans +yelping_since+ review_count + compliments)
summary(fit2)
plot(fit2)

r <- fit2$residuals
left <- min(r)
right <- max(r)
diff <- (right - left)/10
left <- left - diff
right <- right + diff
breaks <- seq(left, right, diff)
hist(r, breaks,main="Histogram of residuals",xlab = "residuals",las=1)
par(new=TRUE)   
plot(density(r), col=2,xlim=c(left,right), yaxt="n", xaxt="n",bty='n', xlab="", ylab="", main='')
```

```{r regression 3}
fit3 <- lm(data = df_ctrl,betweenness ~ review_count + fans )
summary(fit3)
fit3 <- lm(data = df_ctrl,betweenness ~  fans + yelping_since + votes + compliments)
summary(fit3)
plot(fit3)

r <- fit3$residuals
left <- min(r)
right <- max(r)
diff <- (right - left)/10
left <- left - diff
right <- right + diff
breaks <- seq(left, right, diff)
hist(r, breaks,main="Histogram of residuals",xlab = "residuals",las=1)
par(new=TRUE)   
plot(density(r), col=2,xlim=c(left,right), yaxt="n", xaxt="n",bty='n', xlab="", ylab="", main='')
```

```{r regression 4}
fit4 <- lm(data = df_ctrl,eigenvector ~ fans  )
summary(fit4)
fit4 <- lm(data = df_ctrl,eigenvector ~ fans +yelping_since+ votes + review_count + compliments)
summary(fit4)
plot(fit4)

r <- fit4$residuals
left <- min(r)
right <- max(r)
diff <- (right - left)/10
left <- left - diff
right <- right + diff
breaks <- seq(left, right, diff)
hist(r, breaks,main="Histogram of residuals",xlab = "residuals",las=1)
par(new=TRUE)   
plot(density(r), col=2,xlim=c(left,right), yaxt="n", xaxt="n",bty='n', xlab="", ylab="", main='')
```


```{r visualize}
g <- adj_mtx_g
set.seed(12)

# shape: earlier than 2006 as "circle", later as "rectangle"
V(g)[V(g)$yelping_since<2006]$shape <- "circle"
V(g)[V(g)$yelping_since>2005]$shape <- "square"

# color: 
V(g)[V(g)$compliments<500]$color <- "black"
V(g)[V(g)$compliments>500]$color <- "red"

# size: num of fans
V(g)$size <- sqrt(V(g)$fans)/2

# lable size: average star
V(g)$label.cex <- 2^(V(g)$average_stars)/15



plot(g,layout=layout.random)
plot(g,layout=layout.circle)
plot(g,layout=layout.sphere)
plot(g,layout=layout.reingold.tilford)
plot(g,layout=layout.fruchterman.reingold)
plot(g, layout=layout.spring)
tkplot(g)
```

